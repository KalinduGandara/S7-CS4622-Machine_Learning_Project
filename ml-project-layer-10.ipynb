{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "508ed3fb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-23T16:53:43.229084Z",
     "iopub.status.busy": "2023-09-23T16:53:43.228659Z",
     "iopub.status.idle": "2023-09-23T16:53:43.596931Z",
     "shell.execute_reply": "2023-09-23T16:53:43.595868Z"
    },
    "papermill": {
     "duration": 0.375997,
     "end_time": "2023-09-23T16:53:43.599927",
     "exception": false,
     "start_time": "2023-09-23T16:53:43.223930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/speech-based-classification-layer-10/valid.csv\n",
      "/kaggle/input/speech-based-classification-layer-10/train.csv\n",
      "/kaggle/input/speech-based-classification-layer-10/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a075cd65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-23T16:53:43.608751Z",
     "iopub.status.busy": "2023-09-23T16:53:43.608275Z",
     "iopub.status.idle": "2023-09-23T16:53:45.276325Z",
     "shell.execute_reply": "2023-09-23T16:53:45.275284Z"
    },
    "papermill": {
     "duration": 1.674265,
     "end_time": "2023-09-23T16:53:45.278791",
     "exception": false,
     "start_time": "2023-09-23T16:53:43.604526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold,cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6224ea68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-23T16:53:45.286459Z",
     "iopub.status.busy": "2023-09-23T16:53:45.285517Z",
     "iopub.status.idle": "2023-09-23T16:53:55.014466Z",
     "shell.execute_reply": "2023-09-23T16:53:55.013344Z"
    },
    "papermill": {
     "duration": 9.735873,
     "end_time": "2023-09-23T16:53:55.017386",
     "exception": false,
     "start_time": "2023-09-23T16:53:45.281513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/speech-based-classification-layer-10/train.csv\")\n",
    "valid_df = pd.read_csv(\"/kaggle/input/speech-based-classification-layer-10/valid.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/speech-based-classification-layer-10/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1257462a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-23T16:53:55.023762Z",
     "iopub.status.busy": "2023-09-23T16:53:55.023414Z",
     "iopub.status.idle": "2023-09-23T16:53:55.028206Z",
     "shell.execute_reply": "2023-09-23T16:53:55.027227Z"
    },
    "papermill": {
     "duration": 0.010308,
     "end_time": "2023-09-23T16:53:55.030328",
     "exception": false,
     "start_time": "2023-09-23T16:53:55.020020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABELS = [\"label_1\",\"label_2\",\"label_3\",\"label_4\"]\n",
    "models = {}\n",
    "test_predictions = {}\n",
    "random_searches = {}\n",
    "pcas = {}\n",
    "k_bests = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a105012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-23T16:53:55.036624Z",
     "iopub.status.busy": "2023-09-23T16:53:55.036298Z",
     "iopub.status.idle": "2023-09-23T21:18:21.521887Z",
     "shell.execute_reply": "2023-09-23T21:18:21.520363Z"
    },
    "papermill": {
     "duration": 15866.491976,
     "end_time": "2023-09-23T21:18:21.524746",
     "exception": false,
     "start_time": "2023-09-23T16:53:55.032770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: label_1\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "label_1 with param : {'kernel': 'linear', 'gamma': 'scale', 'C': 1.0}\n",
      "Validation Accuracy for label_1 : 0.9586666666666667\n",
      "Processing label: label_2\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] END .................C=1.0, gamma=scale, kernel=sigmoid; total time= 1.9min\n",
      "[CV] END ..................C=1.0, gamma=scale, kernel=linear; total time= 1.3min\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time= 4.0min\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time= 1.3min\n",
      "[CV] END ....................C=0.01, gamma=auto, kernel=poly; total time= 3.4min\n",
      "[CV] END .................C=0.1, gamma=scale, kernel=sigmoid; total time= 3.1min\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time= 4.1min\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time= 3.4min\n",
      "[CV] END .....................C=10, gamma=scale, kernel=poly; total time= 2.1min\n",
      "[CV] END ..................C=0.1, gamma=auto, kernel=sigmoid; total time= 2.8min\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time= 4.6min\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time= 2.5min\n",
      "[CV] END ...................C=50, gamma=scale, kernel=linear; total time= 1.3min\n",
      "[CV] END ...................C=0.01, gamma=scale, kernel=poly; total time= 3.1min\n",
      "[CV] END ..................C=1.0, gamma=scale, kernel=linear; total time= 1.4min\n",
      "[CV] END ..................C=1.0, gamma=scale, kernel=linear; total time= 1.7min\n",
      "[CV] END ...................C=10, gamma=auto, kernel=sigmoid; total time= 2.3min\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time=17.6min\n",
      "[CV] END ....................C=0.01, gamma=auto, kernel=poly; total time= 2.9min\n",
      "[CV] END ....................C=0.01, gamma=auto, kernel=poly; total time= 3.0min\n",
      "[CV] END .................C=0.1, gamma=scale, kernel=sigmoid; total time= 3.3min\n",
      "[CV] END .................C=0.1, gamma=scale, kernel=sigmoid; total time= 3.4min\n",
      "[CV] END .................C=0.01, gamma=auto, kernel=sigmoid; total time= 4.9min\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time= 3.3min\n",
      "[CV] END .....................C=10, gamma=scale, kernel=poly; total time= 1.9min\n",
      "[CV] END .....................C=10, gamma=scale, kernel=poly; total time= 1.9min\n",
      "[CV] END ......................C=10, gamma=auto, kernel=poly; total time= 1.8min\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time= 5.4min\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time= 8.0min\n",
      "[CV] END ...................C=0.01, gamma=scale, kernel=poly; total time= 3.4min\n",
      "[CV] END ...................C=0.01, gamma=scale, kernel=poly; total time= 3.3min\n",
      "[CV] END ...................C=0.01, gamma=scale, kernel=poly; total time= 3.3min\n",
      "[CV] END .................C=1.0, gamma=scale, kernel=sigmoid; total time= 1.9min\n",
      "[CV] END ...................C=10, gamma=auto, kernel=sigmoid; total time= 1.7min\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time= 4.0min\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time= 1.3min\n",
      "[CV] END .................C=0.1, gamma=scale, kernel=sigmoid; total time= 3.2min\n",
      "[CV] END .................C=0.01, gamma=auto, kernel=sigmoid; total time= 4.2min\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time= 4.2min\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time= 3.5min\n",
      "[CV] END ......................C=10, gamma=auto, kernel=poly; total time= 2.1min\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time= 4.7min\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time= 1.2min\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time= 2.5min\n",
      "[CV] END ...................C=50, gamma=scale, kernel=linear; total time= 1.4min\n",
      "[CV] END ...................C=0.01, gamma=scale, kernel=poly; total time= 3.0min\n",
      "[CV] END .................C=1.0, gamma=scale, kernel=sigmoid; total time= 2.2min\n",
      "[CV] END ...................C=10, gamma=auto, kernel=sigmoid; total time= 2.1min\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time= 4.3min\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time=27.2min\n",
      "[CV] END .................C=0.01, gamma=auto, kernel=sigmoid; total time= 5.1min\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time= 3.9min\n",
      "[CV] END .....................C=10, gamma=scale, kernel=poly; total time= 1.9min\n",
      "[CV] END ......................C=10, gamma=auto, kernel=poly; total time= 1.8min\n",
      "[CV] END ..................C=0.1, gamma=auto, kernel=sigmoid; total time= 3.4min\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time= 5.2min\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time= 2.1min\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=  50.7s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=  53.7s\n",
      "[CV] END ...................C=50, gamma=scale, kernel=linear; total time=16.8min\n",
      "label_2 with param : {'kernel': 'poly', 'gamma': 'auto', 'C': 10}\n",
      "Validation Accuracy for label_2 : 0.9497282608695652\n",
      "Processing label: label_3\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "18 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.97924246 0.97713874 0.97745448 0.97650771 0.9748246  0.97531543\n",
      " 0.97927752        nan        nan        nan 0.97478955 0.97710367\n",
      " 0.97384281        nan 0.97433375 0.98004894        nan 0.9732818\n",
      "        nan 0.97447389]\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_3 with param : {'solver': 'lbfgs', 'penalty': 'l2', 'C': 0.1}\n",
      "Validation Accuracy for label_3 : 0.992\n",
      "Processing label: label_4\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   4.2s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   8.2s\n",
      "[CV] END ................C=1.0, penalty=l2, solver=liblinear; total time=  10.3s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=  18.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ....................C=1.0, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=  22.8s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  14.9s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   9.3s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=  10.8s\n",
      "[CV] END .................C=1.0, gamma=scale, kernel=sigmoid; total time= 5.6min\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=12.2min\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time= 6.5min\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time= 2.5min\n",
      "[CV] END ....................C=0.01, gamma=auto, kernel=poly; total time=14.1min\n",
      "[CV] END .................C=0.01, gamma=auto, kernel=sigmoid; total time=18.0min\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=15.3min\n",
      "[CV] END ......................C=10, gamma=auto, kernel=poly; total time= 2.4min\n",
      "[CV] END ..................C=0.1, gamma=auto, kernel=sigmoid; total time=11.1min\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time=20.9min\n",
      "[CV] END ...................C=50, gamma=scale, kernel=linear; total time= 8.7min\n",
      "[CV] END ................C=1.0, penalty=l2, solver=newton-cg; total time=   6.7s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   7.2s\n",
      "[CV] END ................C=1.0, penalty=l2, solver=liblinear; total time=   9.9s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   7.3s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=  10.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=1.0, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=1.0, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=1.0, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END ....................C=1.0, penalty=l2, solver=lbfgs; total time=   2.0s\n",
      "[CV] END ....................C=1.0, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=  15.9s\n",
      "[CV] END ....................C=1.0, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=1.0, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=1.0, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  17.3s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=  47.3s\n",
      "[CV] END ..................C=1.0, gamma=scale, kernel=linear; total time= 1.0min\n",
      "[CV] END ..................C=1.0, gamma=scale, kernel=linear; total time= 1.0min\n",
      "[CV] END ..................C=1.0, gamma=scale, kernel=linear; total time= 1.1min\n",
      "[CV] END ...................C=10, gamma=auto, kernel=sigmoid; total time= 7.4min\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=11.9min\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time= 2.3min\n",
      "[CV] END ....................C=0.01, gamma=auto, kernel=poly; total time=13.7min\n",
      "[CV] END .................C=0.1, gamma=scale, kernel=sigmoid; total time=11.6min\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time= 3.6min\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time= 3.8min\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time= 3.8min\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=15.0min\n",
      "[CV] END ..................C=0.1, gamma=auto, kernel=sigmoid; total time=10.8min\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time=20.6min\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=  58.4s\n",
      "[CV] END ...................C=0.01, gamma=scale, kernel=poly; total time=14.6min\n",
      "[CV] END ..................C=1.0, gamma=scale, kernel=linear; total time= 1.3min\n",
      "[CV] END ..................C=1.0, gamma=scale, kernel=linear; total time= 1.3min\n",
      "[CV] END ...................C=10, gamma=auto, kernel=sigmoid; total time= 1.7min\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time= 1.2min\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time= 1.2min\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time= 1.3min\n",
      "[CV] END ....................C=0.01, gamma=auto, kernel=poly; total time= 3.3min\n",
      "[CV] END .................C=0.1, gamma=scale, kernel=sigmoid; total time= 3.0min\n",
      "[CV] END .................C=0.01, gamma=auto, kernel=sigmoid; total time= 4.2min\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time= 3.3min\n",
      "[CV] END .....................C=10, gamma=scale, kernel=poly; total time= 2.1min\n",
      "[CV] END ......................C=10, gamma=auto, kernel=poly; total time= 2.1min\n",
      "[CV] END ..................C=0.1, gamma=auto, kernel=sigmoid; total time= 2.8min\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time= 1.2min\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time= 1.2min\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time= 2.5min\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time= 1.3min\n",
      "[CV] END ...................C=0.01, gamma=scale, kernel=poly; total time= 3.4min\n",
      "[CV] END .................C=1.0, gamma=scale, kernel=sigmoid; total time= 2.1min\n",
      "[CV] END ..................C=1.0, gamma=scale, kernel=linear; total time= 1.6min\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time= 4.2min\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time=32.1min\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time= 3.6min\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time= 4.1min\n",
      "[CV] END ..................C=0.1, gamma=auto, kernel=sigmoid; total time= 3.5min\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time= 5.3min\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time= 2.1min\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time= 2.1min\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=  51.2s\n",
      "[CV] END ...................C=50, gamma=scale, kernel=linear; total time=25.3min\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   4.3s\n",
      "[CV] END ................C=1.0, penalty=l2, solver=newton-cg; total time=   6.7s\n",
      "[CV] END ................C=1.0, penalty=l2, solver=liblinear; total time=  10.6s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=  56.4s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=  20.6s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   7.6s\n",
      "[CV] END .................C=1.0, gamma=scale, kernel=sigmoid; total time= 5.4min\n",
      "[CV] END ...................C=10, gamma=auto, kernel=sigmoid; total time= 7.0min\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time= 7.2min\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time= 8.7min\n",
      "[CV] END .................C=0.1, gamma=scale, kernel=sigmoid; total time=12.0min\n",
      "[CV] END .................C=0.01, gamma=auto, kernel=sigmoid; total time=17.9min\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=15.4min\n",
      "[CV] END .....................C=10, gamma=scale, kernel=poly; total time= 3.0min\n",
      "[CV] END ..................C=0.1, gamma=auto, kernel=sigmoid; total time=11.5min\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time= 2.2min\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time= 1.9min\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time= 2.5min\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time= 6.8min\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time= 6.8min\n",
      "[CV] END ...................C=50, gamma=scale, kernel=linear; total time= 6.5min\n",
      "[CV] END ...................C=0.01, gamma=scale, kernel=poly; total time=14.1min\n",
      "label_4 with param : {'kernel': 'rbf', 'gamma': 'auto', 'C': 50}\n",
      "Validation Accuracy for label_4 : 0.9706666666666667\n"
     ]
    }
   ],
   "source": [
    "# Loop through each label for classification\n",
    "for label in LABELS:\n",
    "    print(f\"Processing label: {label}\")\n",
    "\n",
    "    # Data Pre-processing\n",
    "    # Separate features and labels\n",
    "    train_X = train_df.dropna(subset=[label]).drop(LABELS, axis=1)\n",
    "    train_y = train_df.dropna(subset=[label])[label].astype(int)\n",
    "    valid_X = valid_df.dropna(subset=[label]).drop(LABELS, axis=1)\n",
    "    valid_y = valid_df.dropna(subset=[label])[label].astype(int)\n",
    "\n",
    "    # Compute class weights for handling class imbalance\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_y), y=train_y)\n",
    "    class_weight_dict = {cls: weight for cls, weight in zip(np.unique(train_y), class_weights)}\n",
    "\n",
    "    # Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    train_X_scaled = scaler.fit_transform(train_X)\n",
    "    valid_X_scaled = scaler.transform(valid_X)\n",
    "\n",
    "    # Dimensionality Reduction with PCA\n",
    "    pca = PCA(n_components=0.99, svd_solver='full')\n",
    "    train_X_pca = pca.fit_transform(train_X_scaled)\n",
    "    valid_X_pca = pca.transform(valid_X_scaled)\n",
    "\n",
    "    k_best = SelectKBest(score_func=f_classif, k=300)\n",
    "    train_X_selected = k_best.fit_transform(train_X_pca, train_y)\n",
    "    valid_X_selected = k_best.transform(valid_X_pca)\n",
    "\n",
    "#     sfs = SequentialFeatureSelector(\n",
    "#         RandomForestClassifier(class_weight=class_weight_dict),\n",
    "#         scoring='accuracy',\n",
    "#         cv=3\n",
    "#     )\n",
    "\n",
    "#     # Fit the SequentialFeatureSelector on training data\n",
    "#     sfs.fit(train_X_pca, train_y)\n",
    "\n",
    "#     # Get the selected feature indices\n",
    "#     selected_feature_indices = list(sfs.k_feature_idx_)\n",
    "\n",
    "#     # Transform the data to include only selected features\n",
    "#     train_X_selected = train_X_pca[:, selected_feature_indices]\n",
    "#     valid_X_selected = valid_X_pca[:, selected_feature_indices]\n",
    "\n",
    "    if label == LABELS[2]:\n",
    "        model= LogisticRegression(class_weight=class_weight_dict)\n",
    "        param_grid = {\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'C': [100, 10, 1.0, 0.1, 0.01],\n",
    "            'solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        model= SVC(class_weight=class_weight_dict)\n",
    "        param_grid = {\n",
    "                'C':  [50, 10, 1.0, 0.1, 0.01],\n",
    "                'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                'gamma': ['scale', 'auto']\n",
    "            }\n",
    "    random_search = RandomizedSearchCV(\n",
    "    estimator=model, param_distributions=param_grid,\n",
    "    n_iter=20, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "\n",
    "    random_search.fit(train_X_selected,train_y)\n",
    "    best_model_estimater = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "\n",
    "    print(f\"{label} with param : {best_params}\")\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    valid_pred = best_model_estimater.predict(valid_X_selected)\n",
    "    accuracy = accuracy_score(valid_y, valid_pred)\n",
    "    print(f\"Validation Accuracy for {label} : {accuracy}\")\n",
    "\n",
    "    # Store the trained model in the dictionary\n",
    "    models[label] = best_model_estimater\n",
    "    random_searches[label] = random_search\n",
    "    pcas[label] = pca\n",
    "    k_bests[label] = k_best\n",
    "\n",
    "\n",
    "    test_X = test_df.drop(columns=[\"ID\"])\n",
    "    test_X_scaled = scaler.transform(test_X)\n",
    "    test_X_pca = pca.transform(test_X_scaled)\n",
    "#     test_X_selected = test_X_pca[:, selected_feature_indices]\n",
    "    test_X_selected = k_best.transform(test_X_pca)\n",
    "\n",
    "    test_predictions[label] = best_model_estimater.predict(test_X_selected)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b49d33c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-23T21:18:21.538184Z",
     "iopub.status.busy": "2023-09-23T21:18:21.536940Z",
     "iopub.status.idle": "2023-09-23T21:18:21.549566Z",
     "shell.execute_reply": "2023-09-23T21:18:21.548553Z"
    },
    "papermill": {
     "duration": 0.022282,
     "end_time": "2023-09-23T21:18:21.552083",
     "exception": false,
     "start_time": "2023-09-23T21:18:21.529801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with the predictions\n",
    "submission_df = pd.DataFrame(test_predictions)\n",
    "\n",
    "# Save the DataFrame to a CSV file with the modified index\n",
    "submission_df.index += 1\n",
    "submission_df.index.name = \"ID\"\n",
    "submission_df.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15884.039376,
   "end_time": "2023-09-23T21:18:24.200783",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-23T16:53:40.161407",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
